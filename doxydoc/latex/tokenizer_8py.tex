\hypertarget{tokenizer_8py}{}\section{Référence du fichier src/parsers/tokenizer.py}
\label{tokenizer_8py}\index{src/parsers/tokenizer.\+py@{src/parsers/tokenizer.\+py}}
\subsection*{Espaces de nommage}
\begin{DoxyCompactItemize}
\item 
 \hyperlink{namespacetokenizer}{tokenizer}
\end{DoxyCompactItemize}
\subsection*{Fonctions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{namespacetokenizer_a30cb15b0950de4e8a9b00b1a42852ddb}{tokenizer.\+yield\+\_\+current\+\_\+word} (pos, current)
\item 
def \hyperlink{namespacetokenizer_a96fa776f6a9120b05064accccb320156}{tokenizer.\+tokenize} (text)
\item 
def \hyperlink{namespacetokenizer_af24eead26991dd3491ff67e6c68dab0f}{tokenizer.\+get\+\_\+words} (text)
\item 
def \hyperlink{namespacetokenizer_a336237c2ca352ce8d955661a22099326}{tokenizer.\+get\+\_\+non\+\_\+maj\+\_\+lines} (text)
\end{DoxyCompactItemize}
\subsection*{Variables}
\begin{DoxyCompactItemize}
\item 
string \hyperlink{namespacetokenizer_a5c2d26110082282c1eb766a0a71dfc9d}{tokenizer.\+\_\+\+I\+N\+T\+E\+R\+N\+A\+L} = \char`\"{}-\/\%\char`\"{}
\item 
list \hyperlink{namespacetokenizer_aa94519b0cea3d01e281f543a1d2a4d2f}{tokenizer.\+\_\+\+E\+X\+C\+E\+P\+T\+\_\+\+I\+N\+T\+E\+R\+N\+A\+L\+\_\+\+S\+E\+C\+O\+N\+D\+\_\+\+P\+A\+R\+T} = \mbox{[}\char`\"{}il\char`\"{}, \char`\"{}elle\char`\"{}, \char`\"{}ils\char`\"{}, \char`\"{}je\char`\"{}, \char`\"{}tu\char`\"{}, \char`\"{}toi\char`\"{}, \char`\"{}moi\char`\"{}, \char`\"{}nous\char`\"{}, \char`\"{}vous\char`\"{}, \char`\"{}le\char`\"{}, \char`\"{}la\char`\"{}, \char`\"{}les\char`\"{}\mbox{]}
\end{DoxyCompactItemize}
